\documentclass[11pt]{amsart}
\usepackage[margin=1in]{geometry}
\usepackage{paralist}

\theoremstyle{definition}
\newtheorem{exercise}{Exercise}
\newtheorem*{definition}{Definition}

\begin{document}
\title{Linear Algebra}
\author{Strang, Section 1.3}
\maketitle

\section{The assignment}
\begin{compactitem}
\item Read section 1.1 of Strang (pages 22-27).
\item Read the following and complete the exercises below.
\end{compactitem}

\section{Matrices}

A \emph{matrix} is a two-dimensional array of numbers like this:
\[
A = \begin{pmatrix} 2 & 1 \\ 1 & 1 \end{pmatrix}.
\]
Sometimes it helps to think of a matrix as a collection of its \emph{rows} which are read across:
\[
M = \begin{pmatrix} \longrightarrow \\ \longrightarrow \end{pmatrix}
\]
and sometimes it helps to think of a matrix as a collection of its \emph{columns} which are read down:
\[
M = \begin{pmatrix} \downarrow & \downarrow \end{pmatrix}.
\]
It is often more clear to describe a matrix by giving the sizes of its rows and columns. An $m$ by $n$ matrix is one having $m$ rows and $n$ columns. It is really easy to get these reversed, so be careful.
For example, this is a $2\times 3$ matrix, because it has two rows and three columns:
\[
B = \begin{pmatrix} 1 & 1 & 2 \\ 3 & 5 & 8 \end{pmatrix}
\]
A matrix is called a \emph{square} matrix when the number of rows and the number of columns is equal. The matrix $A$ that I wrote down above is square because it is a $2\times 2$ matrix.

\subsection{Multiplying Matrices and Vectors}

It is possible to multiply a matrix by a vector like this:
\[
\begin{pmatrix} 1 & 1 & 2 \\ 3 & 5 & 8 \end{pmatrix} \begin{pmatrix} 13 \\ 21 \\ 34 \end{pmatrix} = \begin{pmatrix} 102 \\ 416 \end{pmatrix}
\]
For this to work, it is absolutely crucial that the sizes match up properly. If the matrix is $m$ by $n$, then the vector must have size $n$. In the above example $m = 2$ and $n=3$.

Later, we shall see that the word ``multiplication'' is not really the best choice here. It is better to think of the matrix as ``acting on'' the vector and turning it into a new vector. For now, the word multiplication will serve.

How exactly does one define this matrix-vector multiplication?

\subsubsection{Linear Combination of Columns Approach}
The first way to perform the matrix-vector multiplication is to think of the vector as holding some coefficients for forming a linear combination of the columns of the matrix.
In our example, it looks like this:
\[
\begin{pmatrix} 1 & 1 & 2 \\ 3 & 5 & 8 \end{pmatrix} \begin{pmatrix} 13 \\ 21 \\ 34 \end{pmatrix} =
13 \begin{pmatrix} 1 \\ 3 \end{pmatrix} + 21 \begin{pmatrix} 1 \\ 5 \end{pmatrix} + 34 \begin{pmatrix} 2 \\ 8 \end{pmatrix} =
\begin{pmatrix} 102 \\ 416 \end{pmatrix} .
\]

\subsubsection{Dot Products with the Rows Approach} The second way is to think of the matrix as a bundle of vectors lying along the rows of the matrix, and use the dot product. In our example above, this means that we consider the vectors
\[
r_1 = \begin{pmatrix} 1 \\ 1 \\ 2 \end{pmatrix}, \quad
r_2 = \begin{pmatrix} 3 \\ 5 \\ 8 \end{pmatrix}, \text{ and }
v = \begin{pmatrix} 13 \\ 21 \\ 34 \end{pmatrix}
\]
(notice I've rewritten the rows as columns) and then perform this kind of operation:
\[
\begin{pmatrix} 1 & 1 & 2 \\ 3 & 5 & 8 \end{pmatrix} \begin{pmatrix} 13 \\ 21 \\ 34 \end{pmatrix} =
\begin{pmatrix} r_1 \\ r_2 \end{pmatrix} v =
\begin{pmatrix} r_1 \cdot v \\ r_2 \cdot v \end{pmatrix} =
\begin{pmatrix} 102 \\ 416 \end{pmatrix} .
\]


Two important remarks:
\begin{compactitem}
\item Note that these operations only make sense if the sizes match up properly.
\item Note that the two versions of the operation give you the same results.
\end{compactitem}

\subsection{Matrix Equations}

There are many situations in linear algebra that can be rewritten in the form of an equation that looks like this:
\[\label{eq:matrixeq} \tag{*}
A v = b
\]
where $A$ is a matrix, and $v$ and $b$ are vectors. The interesting case is when we know $A$ and $b$, but we want to find the unknown $v$.

Let's consider the case where you are given some \underline{square} matrix $A$.
\textbf{Sometimes} one can find another matrix $B$ so that no matter what $b$ is chosen in (\ref{eq:matrixeq}), the solution vector takes the form $v = Bb$. When this happens, we say that $A$ is \emph{invertible} and call $B$ the \emph{inverse} of $A$. It is common to use the notation $A^{-1}$ in place of $B$. This is a wonderful situation to be in! Eventually, we will want to figure out some test for when a given matrix is invertible, and find some ways to compute the inverse.

\subsection{A Note about Vectors}

This reading also has a brief introduction to the idea of a set of vectors being \emph{linearly depedent} or \emph{linearly independent}. Strang is coy about the precise definition, so here it is:

\begin{definition} A set of vectors $v_1, v_2, \dots, v_n$ is called \emph{linearly depdendent} when there is some choice of numbers $a_1, a_2, \dots, a_n$ which are not all zero so that the linear combination
\[
a_1 v_1 + a_2 v_2 + \dots + a_n v_n = 0
\]
A set of vectors which is not linearly dependent is called \emph{linearly independent}.
\end{definition}

This is a little funny the first time you read it. Note that for any set of vectors, you can make a linear combination of those vectors come out as $0$. Simply choose all of the coefficients to be zero. But that is so easy to do we call it \emph{trivial}. What the definition is asking is that we find a \emph{nontrival linear combination of the vectors to make zero}.


\section{Sage instructions}

I have made a Sage worksheet file with some basic commands that you might find useful in investigating with matrices. The file is called \texttt{section1\_3.sagews}. It also has some interactive demonstrations about how to deal with matrices.


\section{Questions for Section 1.3}
\setcounter{exercise}{24}

\begin{exercise}
Make an example of a matrix $\left(\begin{smallmatrix} 1 & \bullet \\ -1 & \bullet \end{smallmatrix}\right)$ so that the equation
\[
\begin{pmatrix} 1 & \bullet \\ -1 & \bullet \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 1 \\ -1 \end{pmatrix}
\]
has exactly one solution, or explain why this is not possible.

Interpret this as a statement about $2$-vectors and draw the picture which corresponds.
\end{exercise}

\vspace{1cm}

\begin{exercise}
Make an example of a matrix $\left(\begin{smallmatrix} 4 & 8 & \bullet \\ 3 & 6 & \bullet \\ 1 & 2 & \bullet \end{smallmatrix}\right)$ so that the equation
\[
\begin{pmatrix} 4 & 8 & \bullet \\ 3 & 6 & \bullet \\ 1 & 2 & \bullet \end{pmatrix} \begin{pmatrix} x \\ y \\ z \end{pmatrix} = \begin{pmatrix} 8 \\ 6 \\ 2 \end{pmatrix}
\]
has exactly one solution, or explain why this is not possible.

Interpret this as a statement about $3$-vectors and draw the picture which corresponds.
\end{exercise}

\vspace{1cm}

\begin{exercise}
Make an example of a matrix $\left( \begin{smallmatrix} 2 & -1 \\ \bullet & \bullet \end{smallmatrix}\right)$ so that the equation
\[
\begin{pmatrix} 2 & -1 \\ \bullet & \bullet \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 7 \\ 3 \end{pmatrix}
\]
has exactly one solution, or explain why this is not possible.

Interpret this as a statement about a pair of lines in the plane and draw the picture which corresponds.
\end{exercise}

\vspace{1cm}

\begin{exercise}
Make an example of a matrix $\left( \begin{smallmatrix} 1 & 0 & 1\\ 1 & 1 & 3 \\ \bullet & \bullet & \bullet \end{smallmatrix}\right)$ so that the equation
\[
\begin{pmatrix} 1 & 0 & 1\\ 1 & 1 & 3 \\ \bullet & \bullet & \bullet \end{pmatrix}\begin{pmatrix} x \\ y \\ z \end{pmatrix} = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}
\]
has no solutions, or explain why this is not possible.

Interpret this as a statement about a planes in space and draw the picture which corresponds.

\end{exercise}

\vspace{1cm}

\begin{exercise}
Find a triple of numbers $x$, $y$, and $z$ so that the linear combination
\[
x \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix} + y \begin{pmatrix} 4 \\ 5\\ 6 \end{pmatrix} + z \begin{pmatrix} 7 \\ 8 \\ 9 \end{pmatrix}
\]
yields the zero vector, or explain why this is not possible.

Rewrite the above as an equation which involves a matrix.

Plot the three vectors and describe the geometry of the situation.

\end{exercise}

\vspace{1cm}

\begin{exercise}
The vectors
\[
r_1 = \begin{pmatrix} 1 \\ 4 \\ 7 \end{pmatrix}, \qquad
r_2 = \begin{pmatrix} 2 \\ 5 \\ 8 \end{pmatrix}, \quad \text{ and } \quad
r_3 = \begin{pmatrix} 3 \\ 6 \\ 9 \end{pmatrix}
\]
are linearly dependent because they lie in a common plane (through the origin). Find a normal vector to this plane.

Since the vectors are linearly dependent, there must be (infinitely) many choices of scalars $x$, $y$, and $z$ so that $x r_1 + y r_2 + z r_3 = 0$. Find two sets of such numbers.
\end{exercise}

\vspace{1cm}

\begin{exercise}
Consider the equation
\[
\begin{pmatrix} 2 & 1 \\ 1 & 1 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} b_1 \\ b_2 \end{pmatrix}.
\]
We are interested in being able to solve this for $x$ and $y$ for any given choice of the numbers $b_1$ and $b_2$. Figure out a way to do this by writing $x$ and $y$ in terms of $b_1$ and $b_2$.

Rewrite your solution in the form
\[
\begin{pmatrix} x \\ y \end{pmatrix} = b_1 \begin{pmatrix} \bullet \\ \bullet\end{pmatrix} + b_2 \begin{pmatrix}  \bullet \\ \bullet \end{pmatrix}.
\]

How is this related to the inverse of the matrix $A = \left( \begin{smallmatrix} 2 & 1 \\ 1 & 1 \end{smallmatrix} \right)$?
\end{exercise}

\vspace{1cm}

\begin{exercise}
Find an example of a number $c$ and a vector $\left( \begin{smallmatrix} b_1 \\ b_2 \end{smallmatrix}\right)$ so that the equation
\[
\begin{pmatrix} 3 & 51 \\ c & 17 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} b_1 \\ b_2 \end{pmatrix}
\]
does not have a solution, or explain why no such example exists.

Explain your solution in terms of
\begin{compactitem}
\item lines in the plane,
\item $2$-vectors and linear combinations, and
\item invertibility of a matrix.
\end{compactitem}
\end{exercise}


\end{document}
%sagemathcloud={"zoom_width":100}