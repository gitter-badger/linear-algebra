\documentclass[11pt]{amsart}
\usepackage[margin=1in]{geometry}
\usepackage{paralist}
\usepackage{graphicx}
\usepackage{mathtools}

\theoremstyle{definition}
\newtheorem{exercise}{Exercise}
\newtheorem*{theorem}{Theorem}
\newtheorem*{definition}{Definition}

\begin{document}
\title{Linear Algebra}
\author{Strang, Section 6.2}
\maketitle

\section{The assignment}
\begin{compactitem}
\item Read section 6.2 of Strang (pages 298-307).
\item Read the following.
\item Prepare the items below for presentation.
\end{compactitem}


\section{Diagonalizing Matrices}

The big result here is this:

\begin{theorem} Let $A$ be an $n\times n$ square matrix. Then the following two conditions are equivalent:
\begin{compactitem}
\item There is a basis $\beta= \{ v_1, v_2, \ldots, v_n \}$ for $\mathbb{R}^n$ consisting of eigenvectors for $A$.
\item It is possible to find an invertible matrix $S$ so that $A = S \Lambda S^{-1}$, where $\Lambda$ is a diagonal matrix whose entries are the eigenvalues of $A$.
\end{compactitem}
\end{theorem}

The connection between the two conditions is that the matrix $S$ has as its columns the eigenvectors of $A$. (In fact, that is really the heart of the proof of this theorem. The rest is just details.)

If a matrix satisfies these two conditions, then we say it is \emph{diagonalizable}. We should note right away that not all matrices are diagonalizable. We have already seen examples of matrices where the geometric multiplicity of an eigenvalue is less than the algebraic multiplicity, like $A = \left( \begin{smallmatrix} 5 & 1 \\ 0 & 5 \end{smallmatrix}\right)$. In this case, it becomes impossible to find a basis consisting of eigenvectors.

In a way, this allows us to see something interesting: maybe a matrix really wants to be a diagonal matrix, but we are looking at the transformation $A$ using ``the wrong basis.'' By wrong, here I mean that the standard basis is not the most convenient one, and another one makes our lives easier.

\section{Sage instructions}

I have made a Sage worksheet file with some basic commands that you might find useful. The file is called \texttt{section6\_2.sagews}.


\section{Questions for Section 6.2}
\setcounter{exercise}{146}



\begin{exercise}
Let $e_1, e_2, e_3$ be the standard basis of $\mathbb{R}^3$:
\[
e_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}, \quad e_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}, \quad e_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}.
\]
Make an example of an invertible $3 \times 3$ matrix $S$. Write your matrix as a matrix of column vectors.
\[
S = \begin{pmatrix} | & | & | \\
v_1 & v_2 & v_3 \\
| & | & |
\end{pmatrix}
\]
How do you know that the set $\{ Se_1, Se_2, Se_3 \}$ is a basis for $\mathbb{R}^3$?

What is the connection between $Se_1$, $Se_2$, $Se_3$, $S^{-1}v_1$, $S^{-1}v_2$, $S^{-1}v_3$ and the original vectors $e_1, e_2, e_3, v_1, v_2, v_3$?

Finally, how do we use this to understand the way that the decomposition $A = S\Lambda S^{-1}$ works?
\end{exercise}

\begin{exercise}
Exercise 1 from section 6.2 of Strang.
\end{exercise}

\begin{exercise}
Exercise 2 from section 6.2 of Strang.
\end{exercise}

\begin{exercise}
Exercise 3 from section 6.2 of Strang.
\end{exercise}

\begin{exercise}
Exercise 13 from section 6.2 of Strang.
\end{exercise}

\begin{exercise}
Exercise 19 from section 6.2 of Strang.
\end{exercise}



\end{document}




%sagemathcloud={"zoom_width":100}